{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of `spark.out` were obtained running the program `spark.c` on lab5p7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Cache Size (KiB)  </th><th style=\"text-align: right;\">  Avg Elapsed Time (s)</th><th style=\"text-align: right;\">  # Accesses</th><th style=\"text-align: right;\">  Avg Time per Access (ns)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>4 KiB             </td><td style=\"text-align: right;\">            0.00092925</td><td style=\"text-align: right;\">      409600</td><td style=\"text-align: right;\">                   2.26868</td></tr>\n",
       "<tr><td>8 KiB             </td><td style=\"text-align: right;\">            0.00188254</td><td style=\"text-align: right;\">      819200</td><td style=\"text-align: right;\">                   2.29802</td></tr>\n",
       "<tr><td>16 KiB            </td><td style=\"text-align: right;\">            0.00382021</td><td style=\"text-align: right;\">     1638400</td><td style=\"text-align: right;\">                   2.33167</td></tr>\n",
       "<tr><td>32 KiB            </td><td style=\"text-align: right;\">            0.00756427</td><td style=\"text-align: right;\">     3276800</td><td style=\"text-align: right;\">                   2.30843</td></tr>\n",
       "<tr><td>64 KiB            </td><td style=\"text-align: right;\">            0.0167127 </td><td style=\"text-align: right;\">     6553600</td><td style=\"text-align: right;\">                   2.55015</td></tr>\n",
       "<tr><td>128 KiB           </td><td style=\"text-align: right;\">            0.0396387 </td><td style=\"text-align: right;\">    13107200</td><td style=\"text-align: right;\">                   3.02419</td></tr>\n",
       "<tr><td>256 KiB           </td><td style=\"text-align: right;\">            0.0934102 </td><td style=\"text-align: right;\">    26214400</td><td style=\"text-align: right;\">                   3.56332</td></tr>\n",
       "<tr><td>512 KiB           </td><td style=\"text-align: right;\">            0.203428  </td><td style=\"text-align: right;\">    52428800</td><td style=\"text-align: right;\">                   3.88008</td></tr>\n",
       "<tr><td>1024 KiB          </td><td style=\"text-align: right;\">            0.442602  </td><td style=\"text-align: right;\">   104857600</td><td style=\"text-align: right;\">                   4.22098</td></tr>\n",
       "<tr><td>2048 KiB          </td><td style=\"text-align: right;\">            0.921256  </td><td style=\"text-align: right;\">   209715200</td><td style=\"text-align: right;\">                   4.39289</td></tr>\n",
       "<tr><td>4096 KiB          </td><td style=\"text-align: right;\">            2.06407   </td><td style=\"text-align: right;\">   419430400</td><td style=\"text-align: right;\">                   4.92114</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>Cache Size (KiB)  </th><th style=\"text-align: right;\">  Avg Elapsed Time (s)</th><th style=\"text-align: right;\">  # Accesses</th><th style=\"text-align: right;\">  Avg Time per Access (ns)</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>4 KiB             </td><td style=\"text-align: right;\">            0.00092925</td><td style=\"text-align: right;\">      409600</td><td style=\"text-align: right;\">                   2.26868</td></tr>\\n<tr><td>8 KiB             </td><td style=\"text-align: right;\">            0.00188254</td><td style=\"text-align: right;\">      819200</td><td style=\"text-align: right;\">                   2.29802</td></tr>\\n<tr><td>16 KiB            </td><td style=\"text-align: right;\">            0.00382021</td><td style=\"text-align: right;\">     1638400</td><td style=\"text-align: right;\">                   2.33167</td></tr>\\n<tr><td>32 KiB            </td><td style=\"text-align: right;\">            0.00756427</td><td style=\"text-align: right;\">     3276800</td><td style=\"text-align: right;\">                   2.30843</td></tr>\\n<tr><td>64 KiB            </td><td style=\"text-align: right;\">            0.0167127 </td><td style=\"text-align: right;\">     6553600</td><td style=\"text-align: right;\">                   2.55015</td></tr>\\n<tr><td>128 KiB           </td><td style=\"text-align: right;\">            0.0396387 </td><td style=\"text-align: right;\">    13107200</td><td style=\"text-align: right;\">                   3.02419</td></tr>\\n<tr><td>256 KiB           </td><td style=\"text-align: right;\">            0.0934102 </td><td style=\"text-align: right;\">    26214400</td><td style=\"text-align: right;\">                   3.56332</td></tr>\\n<tr><td>512 KiB           </td><td style=\"text-align: right;\">            0.203428  </td><td style=\"text-align: right;\">    52428800</td><td style=\"text-align: right;\">                   3.88008</td></tr>\\n<tr><td>1024 KiB          </td><td style=\"text-align: right;\">            0.442602  </td><td style=\"text-align: right;\">   104857600</td><td style=\"text-align: right;\">                   4.22098</td></tr>\\n<tr><td>2048 KiB          </td><td style=\"text-align: right;\">            0.921256  </td><td style=\"text-align: right;\">   209715200</td><td style=\"text-align: right;\">                   4.39289</td></tr>\\n<tr><td>4096 KiB          </td><td style=\"text-align: right;\">            2.06407   </td><td style=\"text-align: right;\">   419430400</td><td style=\"text-align: right;\">                   4.92114</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tabulate\n",
    "\n",
    "NR_ITERATIONS = 100  # defined in spark.c\n",
    "CACHE_MIN     = 4    # in KiB\n",
    "\n",
    "sample = [[\"Cache Size (KiB)\", \"Avg Elapsed Time (s)\", \"# Accesses\", \n",
    "               \"Avg Time per Access (ns)\"]]\n",
    "\n",
    "fp = open(\"spark.out\", \"r\")\n",
    "next(fp)             # ignore first line\n",
    "line = fp.readline() # second line, [LOG] line which we ignore, we just \n",
    "                     # read it here to initialize the loop condition\n",
    "\n",
    "cache_size = CACHE_MIN\n",
    "cum_elapsed_time = 0.0\n",
    "elapsed_time_obs_count = 0\n",
    "\n",
    "while line:\n",
    "    line = fp.readline()\n",
    "    \n",
    "    if line.startswith(\"[LOG]\") or line == \"\":\n",
    "        avg_elapsed_time = float(cum_elapsed_time) / elapsed_time_obs_count\n",
    "        # reverse engineering the nr_accesses value: \n",
    "        # in spark.c every stride value simulates the same nr of accesses, \n",
    "        # considering stride = 1 we can see this is the nr of accesses for \n",
    "        # each cache_size\n",
    "        nr_accesses = cache_size * 2**10 * NR_ITERATIONS\n",
    "\n",
    "        sample.append([f\"{cache_size} KiB\", avg_elapsed_time, nr_accesses, \n",
    "                           (avg_elapsed_time / nr_accesses) * 10**9])\n",
    "\n",
    "        cache_size *= 2\n",
    "        cum_elapsed_time = 0.0\n",
    "        elapsed_time_obs_count = 0\n",
    "        continue\n",
    "\n",
    "    _, _, elapsed_time, *_ = line.split(\"\\t\")\n",
    "    cum_elapsed_time += float(elapsed_time)\n",
    "    elapsed_time_obs_count += 1\n",
    "\n",
    "\n",
    "tabulate.tabulate(sample, headers=\"firstrow\", tablefmt=\"html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that the cache capacity is **32 KiB** because that's where we see the first singificant increase in average time per access, prior to array sizes of 64 KiB the time remained somewhat constant. We could be tempted to guess 64 KiB is the cache capacity since 2.55ns to 3.02ns is a much more significant increase, however, looking at the following data in `spark.out`\n",
    "```\n",
    "size\tstride\telapsed(s)\tcycles\n",
    "(...)\n",
    "[LOG]: running with array of size 64 KiB\n",
    "65536\t1\t    0.014075\t14076\t\n",
    "65536\t2\t    0.013435\t13435\t\n",
    "65536\t4\t    0.015363\t15363\t\n",
    "65536\t8\t    0.015878\t15878\t\n",
    "65536\t16\t    0.015519\t15519\t\n",
    "65536\t32\t    0.015379\t15379\t\n",
    "65536\t64\t    0.013368\t13368\t\n",
    "65536\t128\t    0.013804\t13804\t\n",
    "65536\t256\t    0.013328\t13329\t\n",
    "65536\t512\t    0.013572\t13571\t\n",
    "65536\t1024    0.013174\t13174\t\n",
    "65536\t2048    0.028942\t28941\t\n",
    "65536\t4096    0.035842\t35842\t\n",
    "65536\t8192    0.015605\t15605\t\n",
    "65536\t16384   0.015422\t15422\t\n",
    "65536\t32768   0.014697\t14698\n",
    "```\n",
    "we can see the elapsed time for stride values of 2048 and 4096 are much bigger than other observations, this indicates the miss rate has inscreased (even if there were still cache misses happening with different stride values), meaning our L1 cache filled up and cannot hold 64 KiB of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th>Array Size:</th>\n",
    "    <td>8 KiB</td>\n",
    "    <td>16 KiB</td>\n",
    "    <td>32 KiB</td>\n",
    "    <td>64 KiB</td>\n",
    "    <td>128 KiB</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>t2 - t1 (s):</th>\n",
    "    <td>0.00188254</td>\n",
    "    <td>0.00382021</td>\n",
    "    <td>0.00756427</td>\n",
    "    <td>0.0167127 </td>\n",
    "    <td>0.0396387 </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th># accesses[i]:</th>\n",
    "    <td>819200</td>\n",
    "    <td>1638400</td>\n",
    "    <td>3276800</td>\n",
    "    <td>6553600</td>\n",
    "    <td>13107200</td>\n",
    "  <tr>\n",
    "    <th># mean accesse time (ns)</th>\n",
    "    <td>2.29802</td>\n",
    "    <td>2.33167</td>\n",
    "    <td>2.30843</td>\n",
    "    <td>2.55015</td>\n",
    "    <td>3.02419</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the chart, we can identify a group of array sizes whose access time is small, and another group whose access time is significantly higher. We then conclude the cache size to be **64 KiB** because up until that point, all the array values can fit into cache, making the read and write operation times small and relatively constant, regardless of stride. At 128 KiB, all the array content cannot fit simultaneously into cache, resulting in cache misses and, consequently, higher read and write times.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the arrays whose size exceeds the cache capacity (>= 128 KiB) we can determine the cache block's size by seeing which stride value stabilizes the read and write times. For stride values below 16, the access times increase for each stride step, after 16 the read and write times stabilize because we start accessing contents that fall on different cache blocks and, since the entire array cannot entirely fit into cache, this will result in a 100% miss rate. All subsequent strides values will keep the 100% miss rate.\n",
    "\n",
    "We can then determine the cache block's size to be **16 Bytes** (since our array is of type `uint8_t`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 64 KiB size array with a stride of 16, which results in a cache hit (as seen in 2.2) we have an access time of ~370ns. For the 256 KiB array with a stride of 16, which results in a cache miss (as seen in 2.3), we have an access time of ~750ns. Then we can conclude that the miss penalty (the time it takes to load the block from a lower level of the memory hierarchy into the cache) is **750ns - 370ns = 380ns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **a)** \n",
    "The code section shown above is found in `cm1.c`, more specifically starting at line 41, and serves the purpose \n",
    "of testing L1 data cache accesses.\n",
    "In the `cm1.c` program we are analyzing **PAPI_L1_DCM** processor events which are **L1 Cache Misses**, that is, we are testing how many times we tried to fetch data that was not present in the L1 cache and needed to be loaded into cache from a lower level of the memory hierarchy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **b)**\n",
    "Resulting graph from running `./cm1_proc.sh` with the data found in `cm1.out`\n",
    "![Average nr of misses and stride variation graph](graph.png)\n",
    "The *x* axis represents the stride values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **c)** \n",
    "- The L1 cache is **32 KiB**. We can see a significant increase in the miss rate at 64 KiB of array size while the miss rate remains rather constant for lower array size values. In particular, for 32 KiB we have an average miss rate of ~0 (not absolute 0 because of other program values that might be getting stored in cache) meaning this is the highest size of the array that totally fit into cache."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the array whose size exceeds the cache capacity (64 KiB) we see the miss rate becoming 1 at the stride value of **64**. This indicates that, at this stride value, we start accessing elements of the array that fall on different blocks of the L1 cache, meaning we will always need to load a new block into the cache for every access, resulting in a 100% miss rate. Since our array is of type `uint8_t` this means the cache block must be **64 B** in size. For smaller stride values, say of 32, we can see the miss rate decreases, this is because we make two consequent accesses to data in the same block, only needing to load data into the cache half of the times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **a)** \n",
    "In order to analyze the characteristics of the L2 Cache we changed the events type count from **PAPI_L1_DCM** to **PAPI_L2_DCM**. We also changed the **CACHE_MIN** value to 64 KiB since this was the first value with which we started having cache misses on L1 cache and also changed **CACHE_MAX** to 1 MiB.\n",
    "\n",
    "This way we can analyze the L2 Cache misses using PAPI, the **CACHE_MAX** value was increased because L2 Cache is much bigger and lower values might not trigger cache misses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **b)** \n",
    "\n",
    "![Average number of misses in L2](cm2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **c)** \n",
    "- We can see two big increases in average misses, one at 256KiB and another one at 512KiB. The jump from 256 to 512 is much more significant, indicating our L2 might have been fully filled. We can then conclude our L2 cache capacity to be **256KiB**\n",
    "- I have no idea what the block size is\n",
    "- How do I check associativity rules?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **a)** \n",
    "Each matrix has 512 by 512 entries, each entry of size 2B (values of type int16_t), then each matrix will take up $512^2 * 2$B = $2^{19}$ B = **512 KiB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **b)**\n",
    "```\n",
    "After resetting counter 'PAPI_L1_DCM' [x10^6]: 0.000000\n",
    "After resetting counter 'PAPI_LD_INS' [x10^6]: 0.000000\n",
    "After resetting counter 'PAPI_SR_INS' [x10^6]: 0.000000\n",
    "After stopping counter 'PAPI_L1_DCM'  [x10^6]: 135.052581\n",
    "After stopping counter 'PAPI_LD_INS'  [x10^6]: 402.653833\n",
    "After stopping counter 'PAPI_SR_INS'  [x10^6]: 134.218051\n",
    "Wall clock cycles [x10^6]: 716.400162\n",
    "Wall clock time [seconds]: 0.210208\n",
    "Matrix checksum: 2717908992\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of L1 data cache misses: 135.052581 x 10^6\n",
      "Total number of load / store instructions completed: 536.871884 x 10^6\n",
      "Total number of clock cycles: 716.400162 x10^6\n",
      "Elapsed time: 0.210208 seconds\n"
     ]
    }
   ],
   "source": [
    "sf_l1_cache_misses = 135.052581\n",
    "sf_ld_operations = 402.653833\n",
    "sf_sr_operations = 134.218051\n",
    "sf_total_mem_instructions = ld_operations + sr_operations\n",
    "sf_clock_cycles = 716.400162\n",
    "sf_wall_clock_time = 0.210208\n",
    "\n",
    "print(f\"Total number of L1 data cache misses: {sf_l1_cache_misses} x 10^6\")\n",
    "print(f\"Total number of load / store instructions completed: {sf_total_mem_instructions} x 10^6\")\n",
    "print(f\"Total number of clock cycles: {sf_clock_cycles} x10^6\")\n",
    "print(f\"Elapsed time: {sf_wall_clock_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **c)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit rate = 74.8%\n"
     ]
    }
   ],
   "source": [
    "sf_miss_rate = sf_l1_cache_misses / sf_total_mem_instructions\n",
    "sf_hit_rate = 1 - sf_miss_rate\n",
    "\n",
    "print(f\"Hit rate = {round(sf_hit_rate, 3) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **a)**\n",
    "```\n",
    "After resetting counter 'PAPI_L1_DCM' [x10^6]: 0.000000\n",
    "After resetting counter 'PAPI_LD_INS' [x10^6]: 0.000000\n",
    "After resetting counter 'PAPI_SR_INS' [x10^6]: 0.000000\n",
    "After stopping counter 'PAPI_L1_DCM'  [x10^6]: 4.217954\n",
    "After stopping counter 'PAPI_LD_INS'  [x10^6]: 402.653833\n",
    "After stopping counter 'PAPI_SR_INS'  [x10^6]: 134.218051\n",
    "Wall clock cycles [x10^6]: 656.802860\n",
    "Wall clock time [seconds]: 0.192722\n",
    "Matrix checksum: 2717908992\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of L1 data cache misses: 4.217954 x 10^6\n",
      "Total number of load / store instructions completed: 536.871884 x 10^6\n",
      "Total number of clock cycles: 656.80286 x10^6\n",
      "Elapsed time: 0.192722 seconds\n"
     ]
    }
   ],
   "source": [
    "l1_cache_misses = 4.217954\n",
    "ld_operations = 402.653833\n",
    "sr_operations = 134.218051\n",
    "total_mem_instructions = ld_operations + sr_operations\n",
    "clock_cycles = 656.802860\n",
    "wall_clock_time = 0.192722\n",
    "\n",
    "print(f\"Total number of L1 data cache misses: {l1_cache_misses} x 10^6\")\n",
    "print(f\"Total number of load / store instructions completed: {total_mem_instructions} x 10^6\")\n",
    "print(f\"Total number of clock cycles: {clock_cycles} x10^6\")\n",
    "print(f\"Elapsed time: {wall_clock_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit rate = 0.9921434626664115\n"
     ]
    }
   ],
   "source": [
    "miss_rate = l1_cache_misses / total_mem_instructions\n",
    "hit_rate = 1 - miss_rate\n",
    "\n",
    "print(f\"Hit rate = {hit_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **c)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "After resetting counter 'PAPI_L1_DCM' [x10^6]: 0.000000\n",
    "After resetting counter 'PAPI_LD_INS' [x10^6]: 0.000000\n",
    "After resetting counter 'PAPI_SR_INS' [x10^6]: 0.000000\n",
    "After stopping counter 'PAPI_L1_DCM'  [x10^6]: 4.486579\n",
    "After stopping counter 'PAPI_LD_INS'  [x10^6]: 402.915978\n",
    "After stopping counter 'PAPI_SR_INS'  [x10^6]: 134.480196\n",
    "Wall clock cycles [x10^6]: 626.630824\n",
    "Wall clock time [seconds]: 0.183868\n",
    "Matrix checksum: 2717908992\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of L1 data cache misses: 4.486579 x 10^6\n",
      "Total number of load / store instructions completed: 537.396174 x 10^6\n",
      "Total number of clock cycles: 626.630824 x10^6\n",
      "Elapsed time: 0.183868 seconds\n"
     ]
    }
   ],
   "source": [
    "tp_l1_cache_misses = 4.486579\n",
    "tp_ld_operations = 402.915978\n",
    "tp_sr_operations = 134.480196\n",
    "tp_total_mem_instructions = tp_ld_operations + tp_sr_operations\n",
    "tp_clock_cycles = 626.630824\n",
    "tp_wall_clock_time = 0.183868\n",
    "\n",
    "print(f\"Total number of L1 data cache misses: {tp_l1_cache_misses} x 10^6\")\n",
    "print(f\"Total number of load / store instructions completed: {tp_total_mem_instructions} x 10^6\")\n",
    "print(f\"Total number of clock cycles: {tp_clock_cycles} x10^6\")\n",
    "print(f\"Elapsed time: {tp_wall_clock_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit rate = 0.9916512635983151\n"
     ]
    }
   ],
   "source": [
    "tp_miss_rate = tp_l1_cache_misses / tp_total_mem_instructions\n",
    "tp_hit_rate = 1 - tp_miss_rate\n",
    "\n",
    "print(f\"Hit rate = {tp_hit_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference isn't much significant because the matrix transposition doesn't weight in as much as matrix multiplication on the runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **d)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in Hit Rate: 0.24320584305176252\n"
     ]
    }
   ],
   "source": [
    "diff = tp_hit_rate - sf_hit_rate\n",
    "print(f\"Difference in Hit Rate: {diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speedup: 1.1432549437640047\n"
     ]
    }
   ],
   "source": [
    "speedup = sf_wall_clock_time / tp_wall_clock_time\n",
    "print(f\"Speedup: {speedup}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a slight speedup using the transposition, although not super significant. This might indicate the miss penalty was low since the 24% improved hit rate only resulted in a 1.14 speedup. This improvement might not be good, in terms of memory usage (since we need 512KiB aditional bytes in memory) compared to time improvement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
